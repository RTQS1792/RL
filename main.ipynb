{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib as imp\n",
    "import gridenvironment as ge\n",
    "import qtable as qt \n",
    "\n",
    "imp.reload(ge)\n",
    "imp.reload(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinforcement learning parameters\n",
    "α = 0.4  # Learning rate\n",
    "γ = 1.0  # Discount factor\n",
    "ε = 0.3  # Exploration rate\n",
    "NUM_EPISODES = 1000  # Total number of episodes\n",
    "ACTIONS = {\n",
    "    \"0\": (0, 1),  # Move right\n",
    "    \"1\": (1, 0),  # Move down\n",
    "    \"2\": (0, -1),  # Move left\n",
    "    \"3\": (-1, 0),  # Move up\n",
    "    \"4\": (0, 0)  # Stay\n",
    "}\n",
    "\n",
    "env = ge.GridEnvironment(map_name='map2')\n",
    "env.render()\n",
    "Q = qt.QTable(env.map_size, len(ACTIONS), env.num_agents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for episode in tqdm(range(NUM_EPISODES)):\n",
    "    current_state_x = env.reset()\n",
    "    current_action_x = env.choose_action(current_state_x, Q.table, ε, ACTIONS)\n",
    "    while True:\n",
    "        # print(current_state_x, current_action_x)\n",
    "        next_state_x, reward, done = env.step(current_action_x, ACTIONS)\n",
    "        next_action_x = env.choose_action(next_state_x, Q.table, ε, ACTIONS)\n",
    "        # print(next_state_x, next_action_x)\n",
    "        Q.update(current_state_x, current_action_x, reward, next_state_x, next_action_x, α, γ)\n",
    "        # print(current_action_x, next_action_x)\n",
    "        current_state_x, current_action_x = next_state_x, next_action_x\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state_x = env.reset()\n",
    "print(current_state_x)\n",
    "print(env.choose_action(current_state_x, Q.table, 0, ACTIONS))\n",
    "current_state_10 = int(current_state_x, 8)\n",
    "print(Q.table[current_state_10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.show_result(Q.table, ACTIONS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
